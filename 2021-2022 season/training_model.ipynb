{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01982a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report,plot_confusion_matrix,roc_auc_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "232c69a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('Arsenal season 2021_2022 - Sheet1 (2).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13686b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop=['pred_poss','Day','Date','Round','Prediction','GF_prediction', 'GA_prediction','Predicted_formation','pred_gk_Ratings','pred_def_ratings', 'pred_mid_ratings', 'pred_forw_ratings','Opponent','Venue','Result']\n",
    "\n",
    "\n",
    "opponent=pd.get_dummies(df['Opponent'],drop_first=True)\n",
    "venue=pd.get_dummies(df['Venue'],drop_first=True)\n",
    "result=pd.get_dummies(df['Result'],drop_first=True)\n",
    "\n",
    "df=pd.concat([df,opponent,venue,result],axis=1)\n",
    "df=df.iloc[:18]\n",
    "\n",
    "df=df.drop(drop,axis=1)\n",
    "\n",
    "df['Formation'].replace('3-4-2003','3-4-3',inplace=True)\n",
    "df['Formation']=df['Formation'].apply(lambda x:int(x.replace('-','')))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "297df137",
   "metadata": {},
   "source": [
    "    - Cannot use KFold validation because it will cause data leakage.\n",
    "    - Cannot use the usual train test split also since it will cause data leakage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe07ca0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train=df.iloc[:14]\n",
    "test=df.iloc[14:]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cefb0961",
   "metadata": {},
   "source": [
    "    We will just use the data for 14 match (as of 21/12/2021) train our model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477c8864",
   "metadata": {},
   "source": [
    "## Making predictions for match results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ede6753",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train=train.drop(['GF','GA','L','W'],axis=1)\n",
    "y_train=train[['L','W']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e15a95c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test=test.drop(['GF','GA','L','W'],axis=1)\n",
    "y_test=test[['L','W']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edb15add",
   "metadata": {},
   "source": [
    "For predicting score results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "921b0df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_scoring=train[['GF','GA']]\n",
    "y_test_scoring=test[['GF','GA']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a5e24f0",
   "metadata": {},
   "source": [
    "# Testing several models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "id": "511a1dfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_model=[\n",
    "    ('lr',LogisticRegression()),\n",
    "    ('knn',KNeighborsClassifier()),\n",
    "    ('svm',SVC()),\n",
    "    ('rf',RandomForestClassifier()),\n",
    "    ('naive',MultinomialNB()),\n",
    "    ('gbm',GradientBoostingClassifier()),\n",
    "    ('ada',AdaBoostClassifier()),\n",
    "    ('xgb',XGBClassifier(eval_metric='mlogloss'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "id": "300157aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      0.75      0.86         4\n",
      "   macro avg       0.50      0.50      0.50         4\n",
      "weighted avg       0.75      0.75      0.75         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "lr model accuracy score is : 0.75\n",
      "***********************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "knn model accuracy score is : 0.75\n",
      "***********************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "svm model accuracy score is : 0.75\n",
      "***********************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       1.00      0.50      0.67         4\n",
      "   macro avg       0.50      0.33      0.40         4\n",
      "weighted avg       0.75      0.50      0.60         4\n",
      " samples avg       0.50      0.50      0.50         4\n",
      "\n",
      "rf model accuracy score is : 0.5\n",
      "***********************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "naive model accuracy score is : 0.75\n",
      "***********************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         4\n",
      "   macro avg       0.33      0.33      0.33         4\n",
      "weighted avg       0.50      0.50      0.50         4\n",
      " samples avg       0.50      0.50      0.50         4\n",
      "\n",
      "gbm model accuracy score is : 0.5\n",
      "***********************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.67      0.67      0.67         3\n",
      "\n",
      "   micro avg       0.67      0.50      0.57         4\n",
      "   macro avg       0.33      0.33      0.33         4\n",
      "weighted avg       0.50      0.50      0.50         4\n",
      " samples avg       0.50      0.50      0.50         4\n",
      "\n",
      "ada model accuracy score is : 0.5\n",
      "***********************************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      0.67      0.80         3\n",
      "\n",
      "   micro avg       0.67      0.50      0.57         4\n",
      "   macro avg       0.50      0.33      0.40         4\n",
      "weighted avg       0.75      0.50      0.60         4\n",
      " samples avg       0.50      0.50      0.50         4\n",
      "\n",
      "xgb model accuracy score is : 0.5\n",
      "***********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "for name,model in classification_model:\n",
    "    mod=MultiOutputClassifier(model).fit(x_train,y_train)\n",
    "    prediction=mod.predict(x_test)\n",
    "    result=classification_report(y_test,prediction)\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    avg_score=accuracy_score(y_test,prediction)\n",
    "    print(name,'MO {}'.format(avg_score))\n",
    "    print('***********************************************************************************')\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e7b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr knn svm naive "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cec68a3",
   "metadata": {},
   "source": [
    "    There is 4 models that produced the highest accuracy. There is no right answer as to which model produces the best accuracy so probably we will use 4 models to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "1902bace",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL RESULTS : \n",
      "    L  W\n",
      "14  1  0\n",
      "15  0  1\n",
      "16  0  1\n",
      "17  0  1\n",
      "***********************************************************************************\n",
      "***********************************************************************************\n",
      "[[0 0]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      0.75      0.86         4\n",
      "   macro avg       0.50      0.50      0.50         4\n",
      "weighted avg       0.75      0.75      0.75         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "lr MODEL SCORE IS :  75.0 %\n",
      "***********************************************************************************\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "knn MODEL SCORE IS :  75.0 %\n",
      "***********************************************************************************\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "svm MODEL SCORE IS :  75.0 %\n",
      "***********************************************************************************\n",
      "[[0 1]\n",
      " [0 1]\n",
      " [0 1]\n",
      " [0 1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         1\n",
      "           1       0.75      1.00      0.86         3\n",
      "\n",
      "   micro avg       0.75      0.75      0.75         4\n",
      "   macro avg       0.38      0.50      0.43         4\n",
      "weighted avg       0.56      0.75      0.64         4\n",
      " samples avg       0.75      0.75      0.75         4\n",
      "\n",
      "naive MODEL SCORE IS :  75.0 %\n",
      "***********************************************************************************\n"
     ]
    }
   ],
   "source": [
    "classification_model=[\n",
    "    ('lr',LogisticRegression()),\n",
    "    ('knn',KNeighborsClassifier()),\n",
    "    ('svm',SVC()),\n",
    "    ('naive',MultinomialNB()),\n",
    "]\n",
    "\n",
    "\n",
    "print('ACTUAL RESULTS : ')\n",
    "print(y_test)\n",
    "print('***********************************************************************************')\n",
    "print('***********************************************************************************')\n",
    "\n",
    "for name,model in classification_model:\n",
    "    mod=MultiOutputClassifier(model).fit(x_train,y_train)\n",
    "    prediction=mod.predict(x_test)\n",
    "    print(prediction)\n",
    "    result=classification_report(y_test,prediction)\n",
    "    \n",
    "    print(result)\n",
    "    \n",
    "    avg_score=(accuracy_score(y_test,prediction))*100\n",
    "    print(name,'MODEL SCORE IS :  {}'.format(avg_score), '%')\n",
    "    print('***********************************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9d78fd",
   "metadata": {},
   "source": [
    "    Here we can see the most accuract model is Logistic Regression since it predicts the first match as a draw which is the nearest to the actual results (lose)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fa7614a",
   "metadata": {},
   "source": [
    "# Logistic regression hyperparameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6126b199",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=MultiOutputClassifier(estimator=LogisticRegression()),\n",
       "             param_grid={'estimator__C': [100, 10, 1.0, 0.1, 0.01],\n",
       "                         'estimator__penalty': ['l2'],\n",
       "                         'estimator__solver': ['newton-cg', 'lbfgs',\n",
       "                                               'liblinear']},\n",
       "             scoring='accuracy')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d07f738",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d1e82f1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 100, 'estimator__penalty': 'l2', 'estimator__solver': 'lbfgs'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab49220e",
   "metadata": {},
   "source": [
    "    But using grid search, it uses K fold validation hence it causes data leakage. We will try using these hyper for our model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f41ac1d1",
   "metadata": {},
   "source": [
    "# Predicting match results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f211824",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LogisticRegression(C=100)\n",
    "lr=MultiOutputClassifier(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2033c561",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'estimator__C': 100,\n",
       " 'estimator__class_weight': None,\n",
       " 'estimator__dual': False,\n",
       " 'estimator__fit_intercept': True,\n",
       " 'estimator__intercept_scaling': 1,\n",
       " 'estimator__l1_ratio': None,\n",
       " 'estimator__max_iter': 100,\n",
       " 'estimator__multi_class': 'auto',\n",
       " 'estimator__n_jobs': None,\n",
       " 'estimator__penalty': 'l2',\n",
       " 'estimator__random_state': None,\n",
       " 'estimator__solver': 'lbfgs',\n",
       " 'estimator__tol': 0.0001,\n",
       " 'estimator__verbose': 0,\n",
       " 'estimator__warm_start': False,\n",
       " 'estimator': LogisticRegression(C=100),\n",
       " 'n_jobs': None}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "183352d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(x_train,y_train)\n",
    "prediction=lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a5825764",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PREDICTION MADE BY THE MODEL :\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('PREDICTION MADE BY THE MODEL :')\n",
    "prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "69c1f10b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ACTUAL RESULTS :\n",
      "    L  W\n",
      "14  1  0\n",
      "15  0  1\n",
      "16  0  1\n",
      "17  0  1\n",
      "----CLASSIFICATION REPORT-----\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         1\n",
      "           1       1.00      1.00      1.00         3\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         4\n",
      "   macro avg       1.00      1.00      1.00         4\n",
      "weighted avg       1.00      1.00      1.00         4\n",
      " samples avg       1.00      1.00      1.00         4\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('ACTUAL RESULTS :')\n",
    "print(y_test)\n",
    "\n",
    "print('----CLASSIFICATION REPORT-----')\n",
    "print(classification_report(y_test,prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0402fadb",
   "metadata": {},
   "source": [
    "    Somehow the model predicted really well using a higher C value which means it really penalizes the penalty and weaken the penalty values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52e89e4",
   "metadata": {},
   "source": [
    "# Predicting score results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "905f3267",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiOutputClassifier(estimator=LogisticRegression(C=100))"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = LogisticRegression(C=100)\n",
    "lr=MultiOutputClassifier(model)\n",
    "\n",
    "lr.fit(x_train,y_train_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c14ae0d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "scoring_prediction=lr.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74fe8c3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----PREDICTED SCORE RESULTS------\n",
      "[[2. 2.]\n",
      " [2. 0.]\n",
      " [1. 0.]\n",
      " [3. 1.]]\n",
      "----ACTUAL SCORE RESULTS-----\n",
      "     GF   GA\n",
      "14  1.0  2.0\n",
      "15  3.0  0.0\n",
      "16  2.0  0.0\n",
      "17  4.0  1.0\n"
     ]
    }
   ],
   "source": [
    "print('----PREDICTED SCORE RESULTS------')\n",
    "print(scoring_prediction)\n",
    "\n",
    "print('----ACTUAL SCORE RESULTS-----')\n",
    "print(y_test_scoring)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "48b78896",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GF</th>\n",
       "      <th>GA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     GF   GA\n",
       "14  1.0  2.0\n",
       "15  3.0  0.0\n",
       "16  2.0  0.0\n",
       "17  4.0  1.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_scoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98158b61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
